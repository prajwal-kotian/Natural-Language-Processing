{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterFlagging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO1sKpYcOasEfqbSmI3CB1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sjUyB6ZdsOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install -q sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmL6xmfde-W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DS-UDV37iDkq",
        "colab_type": "code",
        "outputId": "eb0c0b47-a263-4a03-ec86-ed153281f87a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "col_list = ['count','class','hate_speech','offensive_language','neither','tweet'] \n",
        "df = pd.read_csv('labeled_data.csv',usecols= col_list)\n",
        "print(len(df['tweet']))\n",
        "\n",
        "train_count = df['count'][0:15000]\n",
        "test_count = df['count'][15000:]\n",
        "train_class = np.array(df['class'][0:15000])\n",
        "test_class = (df['class'][15000:])\n",
        "train_hate_speech = df['hate_speech'][0:15000]\n",
        "test_hate_speech = df['hate_speech'][15000:]\n",
        "train_offensive_language = df['offensive_language'][0:15000]\n",
        "test_offensive_language = df['offensive_language'][15000:]\n",
        "train_neither = df['neither'][0:15000]\n",
        "test_neither = df['neither'][15000:]\n",
        "train_tweet = df['tweet'][0:15000]\n",
        "test_tweet = df['tweet'][15000:]\n",
        "df_pred = df['tweet']\n",
        "df_class = df['class']\n",
        "df_count = df['count']\n",
        "df_hate = df ['hate_speech']\n",
        "df_offensive = df ['offensive_language']\n",
        "df_neither = df['neither']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24783\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqo5bcWzuSEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = Tokenizer (num_words = 88000, oov_token = '<new data>')\n",
        "token.fit_on_texts(train_tweet)\n",
        "training_sequence = np.array(pad_sequences(token.texts_to_sequences((train_tweet)), maxlen = 140  , padding = 'post'))\n",
        "testing_sequence = np.array (pad_sequences(token.texts_to_sequences((test_tweet)), maxlen = 140 , padding = 'post'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4i7Bp3A4xnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc_size = training_sequence.max()+1\n",
        "model = tf.keras.Sequential()\n",
        "model.add(keras.layers.Embedding(voc_size, 16 , input_length = 140))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(32 , activation = 'relu'))\n",
        "model.add(keras.layers.Dense(3, activation= 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFsa0pBK5aCw",
        "colab_type": "code",
        "outputId": "ecc2295c-b0e9-44cb-c53e-ecbe88115a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(optimizer = 'adam' , loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_sequence , train_class, epochs = 30,validation_data=(testing_sequence, test_class), verbose=2 )\n",
        "result = model.evaluate(testing_sequence, test_class)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 140, 16)           402736    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 403,379\n",
            "Trainable params: 403,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "469/469 - 3s - loss: 0.7189 - accuracy: 0.7602 - val_loss: 0.6100 - val_accuracy: 0.7883\n",
            "Epoch 2/30\n",
            "469/469 - 2s - loss: 0.6226 - accuracy: 0.7658 - val_loss: 0.4947 - val_accuracy: 0.8034\n",
            "Epoch 3/30\n",
            "469/469 - 2s - loss: 0.4647 - accuracy: 0.8299 - val_loss: 0.3692 - val_accuracy: 0.8848\n",
            "Epoch 4/30\n",
            "469/469 - 2s - loss: 0.3666 - accuracy: 0.8803 - val_loss: 0.3406 - val_accuracy: 0.8969\n",
            "Epoch 5/30\n",
            "469/469 - 2s - loss: 0.3168 - accuracy: 0.8975 - val_loss: 0.3165 - val_accuracy: 0.8995\n",
            "Epoch 6/30\n",
            "469/469 - 2s - loss: 0.2826 - accuracy: 0.9061 - val_loss: 0.3151 - val_accuracy: 0.9004\n",
            "Epoch 7/30\n",
            "469/469 - 2s - loss: 0.2549 - accuracy: 0.9144 - val_loss: 0.3109 - val_accuracy: 0.9036\n",
            "Epoch 8/30\n",
            "469/469 - 2s - loss: 0.2336 - accuracy: 0.9177 - val_loss: 0.3233 - val_accuracy: 0.9022\n",
            "Epoch 9/30\n",
            "469/469 - 2s - loss: 0.2138 - accuracy: 0.9212 - val_loss: 0.3399 - val_accuracy: 0.8984\n",
            "Epoch 10/30\n",
            "469/469 - 2s - loss: 0.1959 - accuracy: 0.9287 - val_loss: 0.3364 - val_accuracy: 0.9024\n",
            "Epoch 11/30\n",
            "469/469 - 2s - loss: 0.1793 - accuracy: 0.9416 - val_loss: 0.3487 - val_accuracy: 0.8995\n",
            "Epoch 12/30\n",
            "469/469 - 3s - loss: 0.1634 - accuracy: 0.9501 - val_loss: 0.3717 - val_accuracy: 0.8960\n",
            "Epoch 13/30\n",
            "469/469 - 3s - loss: 0.1461 - accuracy: 0.9608 - val_loss: 0.3866 - val_accuracy: 0.8911\n",
            "Epoch 14/30\n",
            "469/469 - 3s - loss: 0.1307 - accuracy: 0.9669 - val_loss: 0.3989 - val_accuracy: 0.8892\n",
            "Epoch 15/30\n",
            "469/469 - 3s - loss: 0.1156 - accuracy: 0.9733 - val_loss: 0.4219 - val_accuracy: 0.8887\n",
            "Epoch 16/30\n",
            "469/469 - 3s - loss: 0.1008 - accuracy: 0.9763 - val_loss: 0.4284 - val_accuracy: 0.8883\n",
            "Epoch 17/30\n",
            "469/469 - 2s - loss: 0.0880 - accuracy: 0.9793 - val_loss: 0.4723 - val_accuracy: 0.8808\n",
            "Epoch 18/30\n",
            "469/469 - 2s - loss: 0.0764 - accuracy: 0.9812 - val_loss: 0.4643 - val_accuracy: 0.8866\n",
            "Epoch 19/30\n",
            "469/469 - 2s - loss: 0.0658 - accuracy: 0.9837 - val_loss: 0.4940 - val_accuracy: 0.8776\n",
            "Epoch 20/30\n",
            "469/469 - 2s - loss: 0.0555 - accuracy: 0.9862 - val_loss: 0.5252 - val_accuracy: 0.8743\n",
            "Epoch 21/30\n",
            "469/469 - 2s - loss: 0.0502 - accuracy: 0.9873 - val_loss: 0.5192 - val_accuracy: 0.8793\n",
            "Epoch 22/30\n",
            "469/469 - 2s - loss: 0.0423 - accuracy: 0.9894 - val_loss: 0.5505 - val_accuracy: 0.8683\n",
            "Epoch 23/30\n",
            "469/469 - 2s - loss: 0.0373 - accuracy: 0.9906 - val_loss: 0.5672 - val_accuracy: 0.8775\n",
            "Epoch 24/30\n",
            "469/469 - 2s - loss: 0.0344 - accuracy: 0.9911 - val_loss: 0.6011 - val_accuracy: 0.8707\n",
            "Epoch 25/30\n",
            "469/469 - 2s - loss: 0.0291 - accuracy: 0.9932 - val_loss: 0.6158 - val_accuracy: 0.8759\n",
            "Epoch 26/30\n",
            "469/469 - 2s - loss: 0.0259 - accuracy: 0.9931 - val_loss: 0.6145 - val_accuracy: 0.8750\n",
            "Epoch 27/30\n",
            "469/469 - 2s - loss: 0.0236 - accuracy: 0.9941 - val_loss: 0.6691 - val_accuracy: 0.8739\n",
            "Epoch 28/30\n",
            "469/469 - 2s - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.6703 - val_accuracy: 0.8566\n",
            "Epoch 29/30\n",
            "469/469 - 2s - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.7483 - val_accuracy: 0.8704\n",
            "Epoch 30/30\n",
            "469/469 - 2s - loss: 0.0172 - accuracy: 0.9957 - val_loss: 0.7242 - val_accuracy: 0.8753\n",
            "306/306 [==============================] - 0s 1ms/step - loss: 0.7242 - accuracy: 0.8753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_p4-054mWmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trump = [\"You haven�۪t seen fireworks until you see @OMAROSA & @piersmorgan go at it again! Let�۪s just say it�۪s no happy reunion��_\",\n",
        "         \"To show you how dishonest some of the press is, they took my funny & (cont) \"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k118Bb-BAueC",
        "colab_type": "code",
        "outputId": "5acda900-606e-495d-bc95-f1f327d6f53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "i =24568\n",
        "pred = np.array (pad_sequences(token.texts_to_sequences((trump)), maxlen = 140 , padding = 'post'))\n",
        "prediction = model.predict(pred)\n",
        "res = np.argmax(prediction[0:1])\n",
        "print(trump)\n",
        "if res == 0:\n",
        "  print('This is flagged as Hate speech')\n",
        "elif res == 1:\n",
        "  print('This is offensive content')\n",
        "else:\n",
        "  print('This doesn\\'t voilate basic human decency')\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['You haven�۪t seen fireworks until you see @OMAROSA & @piersmorgan go at it again! Let�۪s just say it�۪s no happy reunion��_', 'To show you how dishonest some of the press is, they took my funny & (cont) ']\n",
            "This is offensive content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}